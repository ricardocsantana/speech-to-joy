{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff11778e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, time\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "def parse_time(time_str):\n",
    "    \"\"\"Convert time string to datetime object.\"\"\"\n",
    "    time_str = time_str.replace(\",\", \".\")\n",
    "    _, minutes, seconds = time_str.split(\":\")\n",
    "    return float(minutes) * 60 + float(seconds)\n",
    "\n",
    "buffer = 5.0  # Buffer time in seconds\n",
    "\n",
    "for file in os.listdir(\"output_ratings\"):\n",
    "    person = file.split(\"_\")[0].strip(\"P\")\n",
    "    print(f\"Processing file: {file} for person {person}\")\n",
    "    if file.endswith(\".xlsx\"):\n",
    "        file_path = os.path.join(\"output_ratings\", file)\n",
    "        df = pd.read_excel(file_path)\n",
    "        df[\"Exchange text\"] = \"\"\n",
    "        # Find the corresponding exchange text\n",
    "        first_interaction_robot = target_enjoyment_df.loc[target_enjoyment_df[\"PID\"] == int(person), \"Q1-Robot\"].values[0]\n",
    "        exchange_text_df = pd.read_excel(f\"exchange-data/exchange_data-P{person}-{first_interaction_robot}.xlsx\")\n",
    "        for i, row in df.iterrows():\n",
    "            start_time = parse_time(row[\"Start Time\"])\n",
    "            end_time = parse_time(row[\"End Time\"])\n",
    "            all_user_utterances = []\n",
    "            turn = row[\"Turn ID\"]\n",
    "            last = \"r\"\n",
    "\n",
    "            for j, exchange_row in exchange_text_df.iterrows():\n",
    "                \n",
    "                if (start_time < parse_time(exchange_row[\"Start Time\"])) and (end_time > parse_time(exchange_row[\"End Time\"])):\n",
    "                            df.at[i, \"Exchange text\"] += exchange_row[\"Utterance\"] + \" \"\n",
    "                            if exchange_row[\"Utterance\"].startswith(\"User: \"):\n",
    "                                last = \"u\"\n",
    "                                all_user_utterances.append({\"start\": exchange_row[\"Start Time\"], \"end\": exchange_row[\"End Time\"], \"text\": exchange_row[\"Utterance\"], \"length\": len(exchange_row[\"Utterance\"])})\n",
    "                            else:\n",
    "                                last = \"r\"\n",
    "                elif (start_time < parse_time(exchange_row[\"Start Time\"]) + buffer) and (end_time > parse_time(exchange_row[\"End Time\"])) and (parse_time(exchange_row[\"Start Time\"]) < end_time):\n",
    "                        if exchange_row[\"Utterance\"].startswith(\"Robot: \"):\n",
    "                            df.at[i, \"Exchange text\"] += exchange_row[\"Utterance\"] + \" \"\n",
    "                            last = \"r\"\n",
    "                elif (start_time < parse_time(exchange_row[\"Start Time\"])) and (end_time > parse_time(exchange_row[\"End Time\"]) - buffer):\n",
    "                        if exchange_row[\"Utterance\"].startswith(\"User: \") and last == \"r\":\n",
    "                            df.at[i, \"Exchange text\"] += exchange_row[\"Utterance\"] + \" \"\n",
    "                            all_user_utterances.append({\"start\": exchange_row[\"Start Time\"], \"end\": exchange_row[\"End Time\"], \"text\": exchange_row[\"Utterance\"], \"length\": len(exchange_row[\"Utterance\"])})\n",
    "                            last = \"u\"\n",
    "\n",
    "            if len(all_user_utterances) > 0:\n",
    "                # Sort by length of utterance\n",
    "                all_user_utterances = sorted(all_user_utterances, key=lambda x: x[\"length\"], reverse=True)\n",
    "                # Get the longest user utterance\n",
    "                longest_user_utterance = all_user_utterances[0]\n",
    "                # Trim the longest user utterance audio clip\n",
    "                first_interaction_robot = target_enjoyment_df.loc[target_enjoyment_df[\"PID\"] == int(person), \"Q1-Robot\"].values[0]\n",
    "                audio_file = f\"data/raw/P{person}/audio-{first_interaction_robot}-P{person}.wav\"\n",
    "                start_time = longest_user_utterance[\"start\"].replace(\",\", \".\")\n",
    "                end_time = longest_user_utterance[\"end\"].replace(\",\", \".\")\n",
    "                # Trim the audio file using ffmpeg\n",
    "                output_dir = f\"data/audio/P{person}\"\n",
    "                os.makedirs(output_dir, exist_ok=True)\n",
    "                print(f\"Trimming audio file: {audio_file} from {start_time} to {end_time}\")\n",
    "                trimmed_audio_file = f\"data/audio/P{person}/trimmed_audio-P{person}-{first_interaction_robot}-{turn}.wav\"\n",
    "                print(start_time, end_time)\n",
    "                cmd = [\n",
    "                    \"ffmpeg\",\n",
    "                    \"-ss\", start_time,\n",
    "                    \"-i\", audio_file,\n",
    "                    \"-t\", str(parse_time(end_time) - parse_time(start_time)),\n",
    "                    \"-c\", \"copy\",\n",
    "                    trimmed_audio_file\n",
    "                ]\n",
    "                # run the command; raise CalledProcessError on failure\n",
    "                try:\n",
    "                    result = subprocess.run(\n",
    "                        cmd,\n",
    "                        check=True,\n",
    "                        stdout=subprocess.PIPE,\n",
    "                        stderr=subprocess.PIPE,\n",
    "                        text=True\n",
    "                    )\n",
    "                    print(\"Trimmed successfully:\", trimmed_audio_file)\n",
    "                except subprocess.CalledProcessError as e:\n",
    "                    # print ffmpegâ€™s full error output\n",
    "                    print(\"ffmpeg failed with exit code\", e.returncode)\n",
    "                    print(\"ffmpeg stderr:\\n\", e.stderr)\n",
    "                \n",
    "        os.makedirs(f\"data/text/P{person}\", exist_ok=True)\n",
    "        # Save the updated DataFrame back to Excel\n",
    "        df.to_excel(f\"data/text/P{person}/text-aligned-P{person}.xlsx\", index=False)\n",
    "        # Print the number of entries in the processed file\n",
    "        print(f\"Processed {file} with {len(df)} entries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636ebc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import webrtcvad\n",
    "import collections\n",
    "import contextlib\n",
    "import wave\n",
    "import pydub\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "def trim_silence(audio_path, output_path, aggressiveness=2, frame_duration_ms=30, padding_duration_ms=500):\n",
    "    \"\"\"\n",
    "    Trims silence from the beginning and end of an audio file using VAD.\n",
    "\n",
    "    Args:\n",
    "        audio_path (str): Path to the input audio file.\n",
    "        output_path (str): Path to save the trimmed audio file.\n",
    "        aggressiveness (int): VAD aggressiveness mode (0-3). Higher values are less\n",
    "                             likely to classify non-speech as speech. Default: 1.\n",
    "        frame_duration_ms (int): Duration of each audio frame for VAD (10, 20, or 30). Default: 30.\n",
    "        padding_duration_ms (int): Duration of silence to keep before the first speech\n",
    "                                   and after the last speech segment (in ms). Default: 300.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if trimming was successful and file saved, False otherwise.\n",
    "    \"\"\"\n",
    "    print(f\"Loading audio file: {audio_path}\")\n",
    "    try:\n",
    "        # Load audio using pydub - handles format conversion\n",
    "        audio = pydub.AudioSegment.from_file(audio_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Input file not found at {audio_path}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading audio file: {e}\")\n",
    "        return False\n",
    "\n",
    "    # Ensure audio is mono and 16-bit PCM for webrtcvad compatibility\n",
    "    # webrtcvad supports 8000, 16000, 32000, 48000 Hz sample rates\n",
    "    sample_rate = audio.frame_rate\n",
    "    supported_rates = [8000, 16000, 32000, 48000]\n",
    "    if sample_rate not in supported_rates:\n",
    "        # Choose the closest supported rate (preferring higher rates for quality)\n",
    "        target_rate = 32000\n",
    "        print(f\"Warning: Sample rate {sample_rate}Hz not directly supported by webrtcvad. Resampling to {target_rate}Hz.\")\n",
    "        try:\n",
    "            audio = audio.set_frame_rate(target_rate)\n",
    "            sample_rate = target_rate\n",
    "        except Exception as e:\n",
    "            print(f\"Error resampling audio: {e}\")\n",
    "            return False\n",
    "\n",
    "    if audio.channels > 1:\n",
    "        print(f\"Converting audio to mono.\")\n",
    "        audio = audio.set_channels(1)\n",
    "\n",
    "    if audio.sample_width != 2: # 2 bytes = 16 bits\n",
    "        print(f\"Converting audio to 16-bit PCM.\")\n",
    "        audio = audio.set_sample_width(2)\n",
    "\n",
    "    print(f\"Audio Properties for VAD: Rate={sample_rate}Hz, Channels={audio.channels}, SampleWidth={audio.sample_width} bytes\")\n",
    "\n",
    "    vad = webrtcvad.Vad(aggressiveness)\n",
    "\n",
    "    # Calculate frame size in bytes\n",
    "    bytes_per_sample = audio.sample_width\n",
    "    samples_per_frame = int(sample_rate * frame_duration_ms / 1000)\n",
    "    frame_size_bytes = samples_per_frame * bytes_per_sample\n",
    "\n",
    "    # Get raw audio data\n",
    "    raw_audio_data = audio.raw_data\n",
    "\n",
    "    num_frames = len(raw_audio_data) // frame_size_bytes\n",
    "    print(f\"Processing {num_frames} frames of {frame_duration_ms}ms each...\")\n",
    "\n",
    "    speech_start_ms = -1\n",
    "    speech_end_ms = -1\n",
    "    found_speech = False\n",
    "\n",
    "    for i in range(num_frames):\n",
    "        start_byte = i * frame_size_bytes\n",
    "        end_byte = start_byte + frame_size_bytes\n",
    "        frame = raw_audio_data[start_byte:end_byte]\n",
    "\n",
    "        # Ensure the frame has the correct number of bytes (important for the last frame)\n",
    "        if len(frame) < frame_size_bytes:\n",
    "            # Pad the last frame with silence if necessary\n",
    "            # frame += b'\\x00' * (frame_size_bytes - len(frame)) # Alternatively, skip last frame\n",
    "            continue # Skip incomplete frame at the end\n",
    "\n",
    "        try:\n",
    "            is_speech = vad.is_speech(frame, sample_rate)\n",
    "            current_time_ms = i * frame_duration_ms\n",
    "\n",
    "            if is_speech:\n",
    "                if not found_speech:\n",
    "                    speech_start_ms = current_time_ms\n",
    "                    found_speech = True\n",
    "                # Always update the end time when speech is detected\n",
    "                speech_end_ms = current_time_ms + frame_duration_ms # End time is start + duration\n",
    "\n",
    "        except Exception as e:\n",
    "            # webrtcvad can sometimes throw errors on invalid frame lengths etc.\n",
    "            print(f\"Error processing frame {i}: {e}\")\n",
    "            continue\n",
    "\n",
    "    if not found_speech:\n",
    "        print(\"No speech detected in the audio file.\")\n",
    "        # Optionally save the original or an empty file, here we just return False\n",
    "        return False\n",
    "\n",
    "    # Apply padding\n",
    "    start_trim_ms = max(0, speech_start_ms - padding_duration_ms)\n",
    "    end_trim_ms = min(len(audio), speech_end_ms + padding_duration_ms) # len(audio) is in ms\n",
    "\n",
    "    print(f\"Detected speech from {speech_start_ms}ms to {speech_end_ms}ms\")\n",
    "    print(f\"Trimming audio from {start_trim_ms}ms to {end_trim_ms}ms (including padding)\")\n",
    "\n",
    "    # Trim the audio using pydub slicing\n",
    "    trimmed_audio = audio[start_trim_ms:end_trim_ms]\n",
    "\n",
    "    # Export the trimmed audio\n",
    "    try:\n",
    "        # Determine output format from the output file extension\n",
    "        output_format = os.path.splitext(output_path)[1][1:]\n",
    "        if not output_format: # Default to wav if no extension\n",
    "            output_format = \"wav\"\n",
    "            output_path += \".wav\"\n",
    "            print(f\"No output format specified, defaulting to WAV. Saving to {output_path}\")\n",
    "\n",
    "        print(f\"Saving trimmed audio to: {output_path} (Format: {output_format})\")\n",
    "        trimmed_audio.export(output_path, format=output_format)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving trimmed audio file: {e}\")\n",
    "        return False\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    for person in range(4, 43):\n",
    "        input_dir = f\"data/audio/P{person}\"\n",
    "        output_dir = f\"data/audio_vad_500/P{person}\"\n",
    "        # Create output directory if it doesn't exist\n",
    "\n",
    "        if output_dir and not os.path.exists(output_dir):\n",
    "            print(f\"Creating output directory: {output_dir}\")\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "        for file in os.listdir(input_dir):\n",
    "            if file.endswith(\".wav\"):\n",
    "                input_path = os.path.join(input_dir, file)\n",
    "                output_path = os.path.join(output_dir, file)\n",
    "                print(f\"Trimming silence from {input_path} to {output_path}\")\n",
    "                success = trim_silence(\n",
    "                    audio_path=input_path,\n",
    "                    output_path=output_path,\n",
    "                )\n",
    "                if success:\n",
    "                    print(\"Trimming complete.\")\n",
    "                else:\n",
    "                    print(\"Trimming failed.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
