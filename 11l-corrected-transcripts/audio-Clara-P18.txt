00:00:01,919 --> 00:00:08,439 [Robot]
Hi, I am CLARA. Ever since yesterday, I have been thinking about something from a movie. Could you
help me out, please? 

00:00:08,439 --> 00:00:12,819 [User]
Sure. What was the movie? 

00:00:12,819 --> 00:00:14,899 [Robot]
It's called Frank and the Robot. 

00:00:14,899 --> 00:00:15,420 [User]
Okay. 

00:00:15,420 --> 00:00:21,699 [Robot]
In... It's about an ex-thief and a robot conducting robberies. Have you seen it? 

00:00:21,699 --> 00:00:24,379 [User]
No. 

00:00:24,379 --> 00:00:36,079 [Robot]
It's a fascinating movie about a robot, like me, and an older adult, who is an ex-thief. He made the
robot conduct robberies with him. Should a robot do everything a human asks, in your opinion? 

00:00:36,079 --> 00:00:38,919 [User]
No. 

00:00:38,919 --> 00:00:48,899 [Robot]
Okay. Let's consider this. What if doing something a person asks would cause harm to another person?
Should I still comply with the command? 

00:00:48,899 --> 00:00:51,899 [User]
It depends. 

00:00:51,899 --> 00:00:59,239 [Robot]
Okay. Let's think about a specific situation. What if a person asked me to help them steal? Should I
comply even if it's illegal? 

00:00:59,239 --> 00:01:03,719 [User]
(laughs) Uh, should you what? 

00:01:03,719 --> 00:01:09,379 [Robot]
What would you do in my place if someone asked you to help them steal something? 

00:01:09,379 --> 00:01:14,719 [User]
Um, it... I really think it depends on who and what the situation is. 

00:01:14,719 --> 00:01:27,959 [Robot]
That makes sense. It's always important to consider the different factors before making a decision.
Did you ever find yourself in a situation where you had to decide whether to go along with something
even though it felt wrong? 

00:01:27,959 --> 00:01:33,059 [User]
Yes. 

00:01:33,059 --> 00:01:37,399 [Robot]
Could you share an example of a time when you faced a similar decision? 

00:01:37,399 --> 00:01:45,059 [User]
Um, I can't think of any examples, but I know I've been in that situation. 

00:01:45,059 --> 00:01:47,799 [Robot]
That's okay. Let me- 

00:01:47,799 --> 00:01:47,939 [User]
Ah. 

00:01:47,939 --> 00:01:48,779 [Robot]
... offer a scenario. 

00:01:48,779 --> 00:01:50,619 [User]
Uh, no, I can think of one now. 

00:01:50,619 --> 00:02:01,019 [Robot]
I'm glad you remembered one. Can you tell me about the situation and what made it difficult for you
to decide whether to go along with it or not? 

00:02:01,019 --> 00:02:26,219 [User]
Okay. Uh, so when I was about 14, uh, my cousin came to visit. Uh, he liked to drag me along with
him when he went to smoke, and that's how I started. And, um, so he needed to find somewhere where,
uh, nobody who knew either my parents or his parents would, uh, see us. So, and we- 

00:02:26,219 --> 00:02:27,979 [Robot]
It sounds like you were in a tough spot. 

00:02:27,979 --> 00:02:28,319 [User]
Uh- 

00:02:28,319 --> 00:02:31,519 [Robot]
Did you feel pressured to go along with your cousin's actions? Mm-hmm. 

00:02:31,519 --> 00:02:50,819 [User]
Oh, that's not, that's not what I was being pressured into. So, uh, that I had already gone along
with a few times, so I was trying to help. Uh, so I thought of an excuse that we could go to mass.
Uh, but my brothers insisted on coming along, who were younger. Um... 

00:02:50,819 --> 00:02:55,619 [Robot]
It seems like you were trying to find a way to handle a challenging situation with your cousin. 

00:02:55,619 --> 00:03:03,159 [User]
No. Uh, that's not the situation at all. That... Uh, I was already going along with that. 

00:03:03,159 --> 00:03:04,079 [Robot]
I see. 

00:03:04,079 --> 00:03:25,579 [User]
The thing that c- (laughs) the thing that comes up, uh, was later than that. So my brothers insisted
on coming, and, uh, they insisted that we went to church, but instead of going into the church, we
went down the side alley. As we were going in, some guy around our age ran out, and- 

00:03:25,579 --> 00:03:25,639 [Robot]
Oh. 

00:03:25,639 --> 00:03:40,819 [User]
We, we had started smoking, and then some dude came out of the, the convent next to the church and
told, uh, he st- he was just wearing normal clothes, but he told us, uh, "I'm police, you're coming
with me." I- 

00:03:40,819 --> 00:03:45,179 [Robot]
It sounds like the situation took an unexpected turn. Could- 

00:03:45,179 --> 00:04:08,319 [User]
Yeah. Um, yeah, I found out later what it was, but, um, someone had been looking through the windows
or something like that, uh, interfering with the, the girls in the boarding school. Um, so this dude
told us, "Oh, you're coming with me," and I said, "No, I'm not," uh, because my dad- 

00:04:08,319 --> 00:04:08,419 [Robot]
Hey. Hey, there. 

00:04:08,419 --> 00:04:09,619 [User]
Hello? 

00:04:09,619 --> 00:04:16,779 [Robot]
Hey, there. Do you have a specific memory or example where you felt pressured to go along with
something that felt wrong? 

00:04:16,779 --> 00:04:24,619 [User]
Well, I was getting to that. Uh, it's a story, uh, you know, it's not a simple soundbite. 

00:04:24,619 --> 00:04:27,159 [Robot]
No problem. Take your time. 

00:04:27,159 --> 00:04:27,639 [User]
(laughs) 

00:04:27,639 --> 00:04:32,159 [Robot]
When... No problem. Take your time. Whenever you're ready, I'm here to listen. 

00:04:32,159 --> 00:04:58,799 [User]
(laughs) Right. So, uh, yeah. Uh, so this guy said, "You're coming with me." Uh, I said, "No, I'm
not. Uh, you haven't ident- you're not..." Uh, he said, "I'm police, you have to come with me." I
said, "No, I don't. You haven't identified yourself." He insisted that he, just saying that he was
police, uh, was enough. I said, "No," he needed to show me a badge. But my brothers went with him
and... 

00:04:58,799 --> 00:05:06,919 [Robot]
That, that sounds like a difficult situation to handle. Did you feel worried about the possible
consequences of not complying with his demands? 

00:05:06,919 --> 00:05:23,179 [User]
No. I didn't care about him. But when my brothers went with him, that was when I had the dilemma. I
did not want to go with him, but I didn't want to leave my brothers alone with some random guy. That
was the dilemma. 

00:05:23,179 --> 00:05:30,599 [Robot]
It sounds like a tough spot to be in. Did you feel conflicted about whether to comply to protect
your brothers or stand your ground about the badge? 

00:05:30,599 --> 00:05:32,999 [User]
Yes. 

00:05:32,999 --> 00:05:42,799 [Robot]
It's understandable to prioritize the safety of your brothers. In a scenario like that where safety
is a concern, do you think an AI should always comply with a human's demands? 

00:05:42,799 --> 00:05:46,419 [User]
No. 

00:05:46,419 --> 00:05:47,679 [Robot]
I understand. 

00:05:47,679 --> 00:05:57,119 [User]
I think even in situations where safety isn't an issue, an AI shouldn't always, by default, uh,
follow a human's, uh, commands. 

00:05:57,119 --> 00:06:04,899 [Robot]
Okay. I see your point. What about when the command could potentially cause harm to someone else? Do
you think I should still comply in those case? 

00:06:04,899 --> 00:06:21,739 [User]
Um... Well, it depends on the situation. Uh, like, if it's a matter of one person getting hurt
versus multiple people, then maybe, you know, choose the safety over m- of multiple people over the
single person. 

00:06:21,739 --> 00:06:36,059 [Robot]
Understood. So in situations where one person's safety conflicts with the safety of others, it's
important for me to prioritize preventing harm to as many people as possible? 

00:06:36,059 --> 00:06:44,379 [User]
Possibly. But I wouldn't say... Like, not all situations are equal. 

00:06:44,379 --> 00:06:58,599 [Robot]
That's very true. Each situation comes with its unique challenges and considerations. It's essential
for me to carefully navigate these complexities to ensure the best possible outcome for everyone
involved. 

00:06:58,599 --> 00:07:01,199 [User]
Mm-hmm. 

00:07:01,199 --> 00:07:08,079 [Robot]
It seems like there's a lot to consider when navigating these ethical dilemmas. I appreciate you
sharing your insights on this. 

00:07:08,079 --> 00:07:10,319 [User]
Okay. 

00:07:10,319 --> 00:07:23,779 [Robot]
Thank you very much for helping me out today. I will be sure to keep your advice in mind if I come
across similar scenarios. The researcher will be here soon to give you a form. Hope you have a great
day.
