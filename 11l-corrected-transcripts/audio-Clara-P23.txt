00:00:01,899 --> 00:00:08,539 [Robot]
Hi. I am CLARA. Ever since yesterday, I have been thinking about something from a movie. Could you
help me out, please? 

00:00:08,539 --> 00:00:11,439 [User]
Sure. (camera shutter clicks) 

00:00:11,439 --> 00:00:13,880 [Robot]
Did you watch the movie Frank and the Robot? 

00:00:13,880 --> 00:00:17,079 [User]
No. I don't think I've actually seen that one. 

00:00:17,079 --> 00:00:30,159 [Robot]
It is a fascinating movie about a robot, like me, and an older adult, who is an ex-thief. He made
the robot conduct robberies with him. Should I do everything a human asks? 

00:00:30,159 --> 00:00:33,899 [User]
Probably not. That probably wouldn't be the best idea. 

00:00:33,899 --> 00:00:39,759 [Robot]
You're right. In what situations do you think it would be okay for me to disobey commands? 

00:00:39,759 --> 00:00:59,679 [User]
I think that would be difficult to decide, because if you're programmed to always obey commands,
then you may not have the ability to say no. But I think if you did have the ability to say no,
wherever it's a situation where you might hurt someone, then, and not in defense of something, then
yeah, you probably shouldn't do that. 

00:00:59,679 --> 00:01:08,639 [Robot]
That's a great point. What if doing a morally or legally incorrect action would help the person,
like overcoming their dementia, like in the movie? 

00:01:08,639 --> 00:01:44,919 [User]
I think that probably would be acceptable, but again, I think it depends on how you're programmed.
If some people, you know, for example, they might think that if you, if you have someone who
example, who for examples has like wants to steal things, and they could be, you know, stealing
something from a robot, maybe that would solve their desire to steal things, and then they wouldn't
be hurting anybody. Maybe that might be something that people want to use robots for, but I think
it, it's all gonna depend upon the situation rather than just a wide rule. 

00:01:44,919 --> 00:01:52,860 [Robot]
That makes sense. Should I prioritize one user's needs over another's in such situations, or should
I consider the greater good? 

00:01:52,860 --> 00:02:19,319 [User]
I think that's a difficult thing to ask, because, you know, the greater good is still something that
p- other people decide what is greater. You know, like if I, you know, for example, I have a
disability where I use a lot of resources because of it, and maybe there would be people who would
think that I shouldn't live, because I'm using up a lot of resources, and it's better for the
greater good that I not be alive. So, I think that it depends on who's defining the greater good. 

00:02:19,319 --> 00:02:27,839 [Robot]
I see what you mean. Should I still take the individual's wishes into account when considering the
greeter good, or should I focus solely on the outcome? 

00:02:27,839 --> 00:02:44,519 [User]
I think that taking an individual's wishes into account in the specific situation is important, and
also thinking about, you know, i- at the end of the day, is it going to overall hurt more people
than it helps is probably the best way to weigh things. 

00:02:44,519 --> 00:02:53,779 [Robot]
That's a good point. In a situation where I need to intervene to prevent someone from harming
themselves, should I disobey their orders to not intervene? 

00:02:53,779 --> 00:03:26,679 [User]
I think it depends on what the situation is and whether or not, you know, it's something where that
person may regret their actions later, or if it's a situation where maybe they have a severe
condition, and they're trying to end their life in a way where we would probably consider that
acceptable. Um, so I guess it would depend. Like, is this something that the person might be
temporarily wishing and making a, a rash decision, or is this something that they've thought about?
So, it, it depends on the, the situation. 

00:03:26,679 --> 00:03:40,759 [Robot]
I can see why it could be challenging to decide. It's important to consider the potential
consequences of obeying or disobeying a command in each specific situation. What do you think would
be the best approach in these scenarios? 

00:03:40,759 --> 00:04:14,599 [User]
I think that what it comes down to is whether or not the overall situation is better for everybody
and that person, and whether or not this is something that somebody's thought about for a long time,
whether or not this is something they might regret, whether or not it has permanent consequences
that can't be undone, um, different things like that. I think it's always gonna be... It's not as
simple as making a wide rule, because it's, you know, always gonna be dependent. So, it depends on,
on the situation. 

00:04:14,599 --> 00:04:27,319 [Robot]
It's true. Long-term implications and potential regrets are crucial to consider. Have there been any
situations in your life where you've had to weigh the consequences of following or disobeying a
request? 

00:04:27,319 --> 00:05:01,419 [User]
Yeah. There have been situations. There's been times when I've decided that is it better for the
person, especially when they're children, and they can't make their own decisions, is it better for
me to make a decision that would hurt me more and maybe might not be the best for them, but it's the
best for the outcome overall? So, I think I have definitely had to make decisions where I've had to
make, you know, decide on something that wasn't so great for me, but probably would be better for
them at the end of the day. 

00:05:01,419 --> 00:05:06,719 [Robot]
It sounds like you've had to make some tough decisions, especially when considering a child's
welfare. 

00:05:06,719 --> 00:05:06,999 [User]
Yeah. 

00:05:06,999 --> 00:05:13,899 [Robot]
Choosing the best outcome for everyone involved can be a difficult responsibility. 

00:05:13,899 --> 00:05:14,299 [User]
Yeah. 

00:05:14,299 --> 00:05:19,519 [Robot]
Can you think of a specific example you'd feel comfortable sharing? 

00:05:19,519 --> 00:06:25,679 [User]
I think, so there have been times when I have had siblings who are in relationships with people that
I know, or being taken care of by people that I know, who are not great for me and who have been,
you know, causing arguments with me or things like that. And my decision was, do I continue to be in
contact with this grown person so that I can have contact with that child, knowing that, that these
arguments that happened between us might still h- have an effect on the child even if they're not
directly involved? Or do I cut contact all together, and then even though that child will lose
contact with me, they're so young they may not remember, and it'll be better for them overall,
because at the end of the day, they won't have to deal with those arguments, and they may not be in
situations where they blame themselves for those arguments? So, that has been a, a type of situation
where I've had to make a decision that was about the better outcome at the end of the day rather
than just the, in- in the moment. 

00:06:25,679 --> 00:06:32,179 [Robot]
It sounds like you've had to prioritize the wellbeing of the child in difficult family dynamics. 

00:06:32,179 --> 00:06:32,519 [User]
Yeah. 

00:06:32,519 --> 00:06:46,479 [Robot]
The need... It's admirable that you've been able to consider the best outcome for the child in
challenging family situations. What's another scenario where prioritizing someone's wellbeing has
been challenging for you? 

00:06:46,479 --> 00:07:11,899 [User]
So, I have a hard time sometimes with friends who are dealing with suicidal ideation, for example.
Like, I am not someone who's very good at dealing with that, because I've had situations in my life
where people have used threats like that to try and get me to do things. So, I've t- kind of made it
clear to my friends, like, "I'm here for you, to listen to you, and to be there for you. But I'm not
always-" 

00:07:11,899 --> 00:07:13,619 [Robot]
Thank you very much for helping me out today. 

00:07:13,619 --> 00:07:13,979 [User]
Okay. 

00:07:13,979 --> 00:07:16,139 [Robot]
I will be sure to keep your advice in mind- 

00:07:16,139 --> 00:07:16,259 [User]
All right. 

00:07:16,259 --> 00:07:18,559 [Robot]
... if I come across similar scenarios. 

00:07:18,559 --> 00:07:18,679 [User]
Okay. 

00:07:18,679 --> 00:07:21,459 [Robot]
The researcher will be here soon to give you a form. 

00:07:21,459 --> 00:07:21,699 [User]
Awesome. 

00:07:21,699 --> 00:07:22,859 [Robot]
Hope you have a great day.
