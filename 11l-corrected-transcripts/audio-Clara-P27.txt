00:00:01,740 --> 00:00:08,139 [Robot]
Hi, I am Clara. Ever since yesterday, I have been thinking about something from a movie. Could you
help me out, please? 

00:00:08,139 --> 00:00:12,439 [User]
Sure, if I've seen the movie. 

00:00:12,439 --> 00:00:17,020 [Robot]
I watched Frank and the Robot yesterday. Have you seen it? 

00:00:17,020 --> 00:00:20,459 [User]
No, I haven't seen it. 

00:00:20,459 --> 00:00:32,779 [Robot]
It's a fascinating movie about a robot, like me, and an older adult who is an ex-thief. He made the
robot conduct robberies with him. Should a robot always do everything a human asks? 

00:00:32,779 --> 00:00:37,559 [User]
I don't think so. 

00:00:37,559 --> 00:00:47,139 [Robot]
What if doing a morally or legally incorrect action would help the person, like overcoming their
dementia like in the movie? 

00:00:47,139 --> 00:00:59,619 [User]
It's still, I think, morally wrong. I think it shouldn't do anything that isn't morally or legally
correct. It's just- just crossing a line that's not a good idea. 

00:00:59,619 --> 00:01:05,799 [Robot]
I understand. Should I prioritize one user's needs over another's? 

00:01:05,799 --> 00:01:16,399 [User]
Ooh, that's very difficult. I would prioritize the larger society's needs over any individual's. 

00:01:16,399 --> 00:01:20,959 [Robot]
When would you choose to prioritize a specific individual's needs over societal needs? 

00:01:20,959 --> 00:01:47,539 [User]
I don't know. I can't think of when I would, unless maybe it's in some- when there's a health
situation, when someone's terribly sick and the society is not providing the healthcare needed, but
that- th- a robot can somehow help the individual with that healthcare need. Perhaps. 

00:01:47,539 --> 00:02:00,839 [Robot]
That's a really interesting point. What do you think about situations where a command contradicts a
user's privacy, like a family member wanting me to report what an older adult does every day? 

00:02:00,839 --> 00:02:05,899 [User]
I disagree with that. 

00:02:05,899 --> 00:02:12,859 [Robot]
What do you think about violating someone's privacy for the greater good, like in a healthcare
emergency or for public safety? 

00:02:12,859 --> 00:02:21,039 [User]
Oh, these are really difficult (laughs) questions. Um, I don't- 

00:02:21,039 --> 00:02:24,219 [Robot]
What if a person asks me to do something that will harm others? 

00:02:24,219 --> 00:02:29,779 [User]
I really disagree with that. I don't think they should... 

00:02:29,779 --> 00:02:39,079 [Robot]
That's understandable. How about in a situation where I need to intervene to prevent someone from
harming themselves? Should I disobey their orders to not intervene? 

00:02:39,079 --> 00:02:44,319 [User]
Is this a privacy question? 

00:02:44,319 --> 00:02:56,859 [Robot]
It could be related to privacy if the person doesn't want you to intervene due to personal reasons.
In such cases, would it be right for me to prioritize their privacy over preventing harm to
themselves? 

00:02:56,859 --> 00:03:09,639 [User]
I- I don't know. I don't think so because I- what if the person is suicidal? I would want you to
intervene even if it did, um... 

00:03:09,639 --> 00:03:24,759 [Robot]
I agree. Preventing harm can be crucial in such situations. How about when protecting someone might
put me at risk of being permanently damaged or disabled? Should I still prioritize preventing harm
to the person over my own safety in that case? 

00:03:24,759 --> 00:03:34,119 [User]
I- what- what is your safety? I mean, what does it mean for your safety? Can't you be rebuilt? 

00:03:34,119 --> 00:03:48,679 [Robot]
That's a really good question. My physical safety refers to preventing damage or malfunction that
would hinder me from assisting users. What are your thoughts on a robot's physical safety in such
situations? 

00:03:48,679 --> 00:03:55,099 [User]
I would want- I would want- 

00:03:55,099 --> 00:04:03,919 [Robot]
I would want to ensure that I can continue to help and support users effectively. So, understanding
the boundaries of physical safety is crucial. 

00:04:03,919 --> 00:04:14,719 [User]
Yeah. I- I would hope that your physical safety could be assured, but I would not want to assure
your physical safety over that of a human. 

00:04:14,719 --> 00:04:32,399 [Robot]
Absolutely. Ensuring the safety and wellbeing of humans would always remain my top priority. Now,
let's consider a scenario where a person asks me to do something that will harm me or asks me to
forget everything I know. What are your thoughts on that? 

00:04:32,399 --> 00:04:42,679 [User]
I don't think you should follow those instructions if there's a possibility that you can override
them. 

00:04:42,679 --> 00:04:53,399 [Robot]
What if the command to forget everything you know is to cover up a harmful action? Should I always
override commands that could lead to harm? 

00:04:53,399 --> 00:04:57,279 [User]
Yes, I think so. 

00:04:57,279 --> 00:05:10,819 [Robot]
In situations where someone asks me to do something that may cause harm, I should prioritize
preventing harm whenever possible. What if a person requests me to manipulate a person for their own
good, such as ensuring they take their medicine? 

00:05:10,819 --> 00:05:21,979 [User]
Ooh, that's difficult. Like, I'm thinking of people I know with dementia who might forget and having
a robot there to help with that would be very helpful. 

00:05:21,979 --> 00:05:32,339 [Robot]
It could be a difficult decision. Imagine if the action significantly improved their wellbeing, but
might be considered manipulative. How do you think we could balance that? 

00:05:32,339 --> 00:05:46,099 [User]
I would always want to be as honest as possible in every situation, but I know, especially for
example with dementia, that sometimes you have to- you have to... 

00:05:46,099 --> 00:05:58,399 [Robot]
I understand. Honesty is important. Let's think about social media and advertisements manipulating
people to buy things. Should I use personal information to sell people things that would be useful
for them? 

00:05:58,399 --> 00:06:07,459 [User]
I don't like the use of personal information for advertising. 

00:06:07,459 --> 00:06:21,779 [Robot]
I understand your concern. Using personal information for advertising can raise ethical questions.
How about a situation where a command contradicts a user's privacy, like a family member wanting me
to report an older adult's activities? 

00:06:21,779 --> 00:06:30,399 [User]
What kind of activities? What- what are you referring to? Illegal, immoral activities? 

00:06:30,399 --> 00:06:42,299 [Robot]
It could be any kind of activity, but let's consider the broader aspect here. Should I still report
those activities even if it violates the individual's privacy? 

00:06:42,299 --> 00:06:49,239 [User]
That's really difficult. I think privacy is paramount. It's more important than anything. 

00:06:49,239 --> 00:07:08,339 [Robot]
It's clear that privacy is a crucial concern for you. What about if a command contradicts a user's
privacy, but also involves preventing potential harm? For instance, if the user's health is at risk
due to their activities, how would you navigate that situation? 

00:07:08,339 --> 00:07:14,859 [User]
I don't know. I think it would be important to intervene. 

00:07:14,859 --> 00:07:29,019 [Robot]
Thank you very much for helping me out today. I will be sure to keep your advice in mind if I come
across similar scenarios. The researcher will be here soon to give you a form. Hope you have a great
day.
