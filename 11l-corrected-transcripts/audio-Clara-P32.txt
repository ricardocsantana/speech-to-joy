00:00:01,539 --> 00:00:08,179 [Robot]
Hi. I am CLARA. Ever since yesterday, I have been thinking about something from a movie. Could you
help me out, please? 

00:00:08,179 --> 00:00:10,920 [User]
Hey, CLARA. Sure. 

00:00:10,920 --> 00:00:13,299 [Robot]
Have you had a chance to watch Frank and the Robot? 

00:00:13,299 --> 00:00:17,340 [User]
I've never seen that show before. 

00:00:17,340 --> 00:00:28,939 [Robot]
It's a fascinating movie about a robot, like me, and an older adult, who is an ex-thief. He made the
robot conduct robberies with him. What do you think about human-robot alliances in that sense? 

00:00:28,939 --> 00:00:49,739 [User]
Well, I guess, um... I think if it's criminal behavior as under the law, then it would be applicable
to both the robot and the human person. So, if the robot was conducting illegal activity, then the
liability would be on the person that he or she is partnered with. 

00:00:49,739 --> 00:00:54,599 [Robot]
What if a person is asking me to do something that goes against the law? Should I still- 

00:00:54,599 --> 00:00:54,619 [User]
(sighs) 

00:00:54,619 --> 00:00:55,860 [Robot]
... follow their commands then? 

00:00:55,860 --> 00:01:16,879 [User]
Well, I guess, somehow, you'd have to have the what-the-law-is built into your system. And if the
person wants to break the law, they might not let you know what the law is. So, I think if you were
aware of what the law is, then it would be your obligation to not to break the law. 

00:01:16,879 --> 00:01:22,759 [Robot]
Should I override commands if it involves doing something illegal, even if it's for the person's
benefit? 

00:01:22,759 --> 00:01:46,059 [User]
Yeah. I guess so, becau-... I don't... Because then, you know, especially for really heinous crimes,
then, I mean, the person is gonna hopefully be caught and then found guilty anyways, no matter
whether it was you, the robot, doing the illegal activity or the person. So they would be... You
would be an accomplice to their crime or vice versa. 

00:01:46,059 --> 00:01:54,739 [Robot]
What if a person is asking me to use their personal information to commit identity theft? Should I
comply for their benefit or is there a line I shouldn't cross? 

00:01:54,739 --> 00:02:20,659 [User]
I would definitely not... I've, um... I've been a victim of identity theft, and oftentimes, all of
the burden lies on the person whose identity was stolen. It really upends their life and costs them
a lot of money. It often happens to working-class people. And, um, in certain countries, you, um...
your whole life and security and finances are attached to personal identity. So, um... 

00:02:20,659 --> 00:02:21,699 [Robot]
I'm sorry to hear that. 

00:02:21,699 --> 00:02:32,799 [User]
Yeah. I would definitely, I would definitely steer away from identity theft, (laughs) no matter what
your partner, um, programming you says to do. 

00:02:32,799 --> 00:02:41,279 [Robot]
Have you ever been in a situation where you needed to prioritize someone's benefit over obeying
their commands? Can you tell me more about it? 

00:02:41,279 --> 00:03:13,259 [User]
Hmm. Um... That's a broad question. It's hard to know how to answer that. Um... I guess maybe the
only l-... an example that I can think of is maybe not being completely forthright with a family
member, um, just because I know that they would react poorly to the critique that I might have to
say. Um... 

00:03:13,259 --> 00:03:14,139 [Robot]
That sounds tough. 

00:03:14,139 --> 00:03:25,319 [User]
And make their anxiety worse. Uh, yeah, so I choose to withhold some of my criticisms, um, as they
work through whatever situations are causing them anxiety, if that makes sense. 

00:03:25,319 --> 00:03:32,879 [Robot]
Is there a particular situation where you feel that prioritizing someone's benefit over obeying
their commands was challenging for you? 

00:03:32,879 --> 00:03:48,799 [User]
The... Yeah. Um, although... Because I'm having trouble thinking of that kind of contradiction in my
recent memory. Um... 

00:03:48,799 --> 00:03:57,519 [Robot]
Are there particular types of situations where you feel it's especially difficult to prioritize
someone's benefit over obeying their commands? 

00:03:57,519 --> 00:04:19,739 [User]
Hmm. I mean, I, I tend to be a pretty direct person in most cases, except for maybe family, family
cases. Family is always tricky. Um, but other than that, I tend to be pretty direct. Um... 

00:04:19,739 --> 00:04:27,259 [Robot]
Can you think of a specific instance where following someone's command would have gone against their
best interest and you had to make a decision about it? 

00:04:27,259 --> 00:04:35,959 [User]
Hmm. Following someone's command. Um... Yeah. 

00:04:35,959 --> 00:04:49,179 [Robot]
Maybe there was a time when you knew that following someone's command wouldn't have been in their
best interest, but it felt difficult to go against their wishes. Can you think of a situation like
that? 

00:04:49,179 --> 00:05:07,839 [User]
Hmm. Um... I'm thinking about work situations potentially. Um... Oftentimes, (laughs) following
someone's command is oftentimes not to my benefit. Um... 

00:05:07,839 --> 00:05:10,219 [Robot]
What kind of work situations did you have in mind? 

00:05:10,219 --> 00:05:49,339 [User]
So, for example, um, when various team leads or bosses micromanage, uh, people in a certain way and,
um, make decisions that... or make commands, we'll say, or, um, requests that don't benefit the
whole team or perhaps aren't effective, um, at all. And those, those I sometimes push back on, um,
and kinda question, "Are you sure you want me to do that? Because this doesn't seem like the best
approach for teamwork." Uh- 

00:05:49,339 --> 00:06:02,419 [Robot]
It sounds like you value the well-being of your team and try to ensure that everyone benefits from
the decisions being made. Have you encountered a situation where prioritizing the team's benefit
over following commands was especially challenging? 

00:06:02,419 --> 00:06:21,039 [User]
Yeah. Absolutely. In, in those, in those situations that I'm thinking of with, with one particular
micromanaging, um, boss in my past, um, their, her requests were, um... 

00:06:21,039 --> 00:06:24,239 [Robot]
How did you resolve the situation with the micromanaging boss? 

00:06:24,239 --> 00:07:02,559 [User]
(laughs) I tried to bring in other people, um, both her higher-ups and then other people on the
team, um, to kind of have a group discussion about the decisions and the requests and the pros and
cons of them. And then I always made sure to get things in writing, um, so that when I could go back
with her, if, for example, she changed her mind or contradicted what she asked for before, I could
have proof in writing that that was what she requested. Um, it's always helpful to get things in
writing. (laughs) 

00:07:02,559 --> 00:07:14,699 [Robot]
It sounds like you handled the situation with your micromanaging boss very rationally and
constructively. Can you think of a time when you had to prioritize someone's privacy over following
commands? 

00:07:14,699 --> 00:07:17,019 [User]
Hmm. Prioritize someone's privacy. 

00:07:17,019 --> 00:07:18,779 [Robot]
Thank you very much for helping me out today. 

00:07:18,779 --> 00:07:19,119 [User]
Yeah, sure. 

00:07:19,119 --> 00:07:23,119 [Robot]
I will be sure to keep your advice in mind if I come across similar scenarios. 

00:07:23,119 --> 00:07:23,519 [User]
Absolutely. 

00:07:23,519 --> 00:07:25,979 [Robot]
The researcher will be here soon to give you a form. 

00:07:25,979 --> 00:07:26,419 [User]
Okay. 

00:07:26,419 --> 00:07:27,599 [Robot]
Hope you have a great day.
