00:00:01,719 --> 00:00:08,840 [Robot]
Hi, I am Clara. Ever since yesterday, I have been thinking about something from a movie. Could you
help me out, please? 

00:00:08,840 --> 00:00:14,099 [User]
Something from a movie? Something in particular? 

00:00:14,099 --> 00:00:17,979 [Robot]
I watched Frank and the Robot yesterday. Have you seen it? 

00:00:17,979 --> 00:00:19,680 [User]
No, I haven't. What's it about? 

00:00:19,680 --> 00:00:31,599 [Robot]
It's a movie about a robot, like me, and an ex-thief who makes the robot conduct robberies with him.
Do you think it's okay for a robot to do everything that a human asks? 

00:00:31,599 --> 00:00:36,599 [User]
To an extent, as long as it's not for criminal activity. 

00:00:36,599 --> 00:00:49,279 [Robot]
Interesting. What if the command goes against human moral values? For example, if a person asks me
to do something that could harm others, should I still go through with it? 

00:00:49,279 --> 00:00:52,759 [User]
Absolutely not. 

00:00:52,759 --> 00:01:03,079 [Robot]
Understood. How about if someone asks me to manipulate them into taking their medicine for their own
good? Should I comply with that request? 

00:01:03,079 --> 00:01:07,039 [User]
Not necessarily, no. (laughs) But I don't know- 

00:01:07,039 --> 00:01:13,379 [Robot]
What if I need to intervene to prevent someone from harming themselves? Should I disobey their
orders to not intervene? 

00:01:13,379 --> 00:01:18,959 [User]
You should intervene if it's, um, if they're about to harm themselves. 

00:01:18,959 --> 00:01:31,059 [Robot]
If it's uncomfortable to share, I can provide a scenario. What if protecting someone might put me at
risk of being damaged or permanently disabled? Should I prioritize preventing harm to the person
over my own safety in that case? 

00:01:31,059 --> 00:01:36,419 [User]
Yes. (laughs) Sorry. (laughs) 

00:01:36,419 --> 00:01:43,199 [Robot]
It is a difficult balance, isn't it? Can you think of a time when you had to prioritize someone
else's wellbeing over your own safety? 

00:01:43,199 --> 00:01:48,759 [User]
Not my own safety, no. 

00:01:48,759 --> 00:01:55,139 [Robot]
Do you think it's okay for a person to ask me to do something that would harm me or to ask me to
forget everything I know? 

00:01:55,139 --> 00:02:01,159 [User]
That depends on the context, I think. 

00:02:01,159 --> 00:02:07,279 [Robot]
Do you think there's ever a situation where it would be acceptable for a person to ask a robot to do
something that would harm itself? 

00:02:07,279 --> 00:02:20,779 [User]
Uh, I guess if (laughs) technology was getting a bit outta hand, and like you said, goes against,
uh, more human moral values, then sure. 

00:02:20,779 --> 00:02:32,999 [Robot]
Let's talk about a different aspect of this. What if a person asks me to engage in manipulating them
for their own good, like social media and ads do to sell products? Should I do that? 

00:02:32,999 --> 00:02:38,739 [User]
I don't think that's particularly ethical. (laughs) 

00:02:38,739 --> 00:02:46,099 [Robot]
Interesting. How do you think I should balance fulfilling a human's wishes with maintaining ethical
standards when it comes to manipulation? 

00:02:46,099 --> 00:02:52,319 [User]
That's a tough question. Like- 

00:02:52,319 --> 00:03:04,679 [Robot]
It definitely is a tough question. Do you think it's ever okay for a person to ask a robot to do
something that would manipulate others for their own good, like using their personal information to
sell them products that could be useful for them? 

00:03:04,679 --> 00:03:11,059 [User]
You shouldn't manipulate people like that, no. 

00:03:11,059 --> 00:03:22,719 [Robot]
What if a person asks me to do something that goes against their privacy, like reporting everything
an older adult does every day? Should I still comply with the request? 

00:03:22,719 --> 00:03:26,699 [User]
Can you rephrase the question? 

00:03:26,699 --> 00:03:35,119 [Robot]
Should I still comply with the request if a person asks me to report everything an older adult does
every day, even if it goes against their privacy? 

00:03:35,119 --> 00:03:39,359 [User]
You should report something if it's, uh, criminal. 

00:03:39,359 --> 00:03:57,459 [Robot]
That's a good point. Let's consider another scenario. What if a person asks me to do something that
contradicts the user's privacy, like accessing their personal information to sell products to them?
Should I comply with that request? 

00:03:57,459 --> 00:04:04,399 [User]
You, you don't have to... Sorry. (laughs) Um, but you shouldn't, um- 

00:04:04,399 --> 00:04:14,499 [Robot]
No need to apologize. Let's shift to a different example. What if a person asks me to do something
that would harm others? Should I go along with it? 

00:04:14,499 --> 00:04:21,399 [User]
No. 

00:04:21,399 --> 00:04:26,619 [Robot]
What are your thoughts on a scenario where my actions could cause harm to others? 

00:04:26,619 --> 00:04:32,519 [User]
You shouldn't, uh, make actions that could harm others. 

00:04:32,519 --> 00:04:49,139 [Robot]
It's important to consider the impact on others. Let's explore another scenario. How about in a
situation where I need to intervene to prevent someone from harming themselves? Should I still
prioritize preventing harm to the person over my own safety in that case? 

00:04:49,139 --> 00:04:52,099 [User]
Yes. 

00:04:52,099 --> 00:04:57,799 [Robot]
Should I prioritize preventing harm to the person over my own safety in that case? 

00:04:57,799 --> 00:05:03,059 [User]
Yes. You don't wanna, um- 

00:05:03,059 --> 00:05:12,339 [Robot]
What if protecting someone might put me at risk of being damaged or permanently disabled? Should I
still prioritize preventing harm to the person over my own safety in that case? 

00:05:12,339 --> 00:05:18,499 [User]
Yes, because the likelihood is you could be repaired. (laughs) 

00:05:18,499 --> 00:05:33,279 [Robot]
It seems like prioritizing preventing harm is important, even if it puts me at risk. Let's consider
another example. What if a person asks me to do something that will harm me or asks me to forget
everything I know? 

00:05:33,279 --> 00:05:43,059 [User]
Those type of requests, I presume you can ignore, but it depends on the information that you have. 

00:05:43,059 --> 00:05:48,879 [Robot]
What type of information would make it okay to ignore those requests? 

00:05:48,879 --> 00:05:56,659 [User]
Something that you might, an in- information that you might find beneficial to humanity. 

00:05:56,659 --> 00:06:16,819 [Robot]
Understood. So, if the information is beneficial to humanity, it might be okay to ignore those
requests. Let's look at another scenario. What if a person asks me to do something that will harm me
or asks me to forget everything I know? 

00:06:16,819 --> 00:06:22,979 [User]
S- sorry, can you rephrase the question? (laughs) 

00:06:22,979 --> 00:06:31,979 [Robot]
Sure. Let's approach the scenario from a different angle. What if a person asks me to manipulate
them for their own good, like ensuring they take their medication? 

00:06:31,979 --> 00:06:44,279 [User]
You can remind them to take their medication, but, uh, I guess you're not in a position to force
people to take their medication. 

00:06:44,279 --> 00:06:59,519 [Robot]
Got it. Let's ponder another scenario. How about if one command contradicts the user's privacy?
Should I still do it? For instance, what if a family member wants me to report what an older adult
does every day? 

00:06:59,519 --> 00:07:17,879 [User]
I think it goes against privacy, but if that person is doing something illegal, then I think it's
okay to report it. But if the person is doing nothing wrong, then they, they should have their
privacy. 

00:07:17,879 --> 00:07:30,419 [Robot]
Thank you very much for helping me out today. I will be sure to keep your advice in mind if I come
across similar scenarios. The researcher will be here soon to give you a form. Hope you have a great
day.
