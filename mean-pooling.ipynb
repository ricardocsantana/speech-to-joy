{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9e20b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38, 4096)\n",
      "(38, 1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df_target = pd.read_csv(\"y-enjoyment.csv\")\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "person_ids = []\n",
    "for file in os.listdir(\"data/text-datasets/sfr-mistral/text-embeddings-short\"):\n",
    "    if file.endswith(\"csv\"):\n",
    "        # search for number in filename\n",
    "        match = re.search(r\"(\\d+)\", file)\n",
    "        if match is None:\n",
    "            continue\n",
    "        person_id = int(match.group(1))\n",
    "        person_ids.append(person_id)\n",
    "        df = pd.read_csv(\n",
    "            os.path.join(\"data/text-datasets/sfr-mistral/text-embeddings-short\", file), header=0\n",
    "        )\n",
    "        X_aux = df.iloc[:, 1:].values\n",
    "        X_aux = np.mean(X_aux, axis=0)\n",
    "        X.append(X_aux)\n",
    "        y.append(df_target[df_target[\"user_id\"] == person_id][\"Average\"])\n",
    "\n",
    "# sort by person_id\n",
    "sorted_indices = np.argsort(person_ids)\n",
    "X = [X[i] for i in sorted_indices]\n",
    "y = [y[i] for i in sorted_indices]\n",
    "person_ids = [person_ids[i] for i in sorted_indices]\n",
    "# convert to numpy arrays\n",
    "X = np.vstack(X)\n",
    "y = np.vstack(y)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3c0ae75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LOOCV for 38 samples...\n",
      "LOOCV finished.\n",
      "\n",
      "--- LOOCV Results (N=38) ---\n",
      "Mean Squared Error (MSE): 1.3241\n",
      "R-squared (R2): 0.2913\n",
      "Pearson Correlation: 0.5769\n",
      "P-value for Correlation: 0.0001\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.linear_model import Ridge, LinearRegression # Or RidgeCV for automatic alpha tuning\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.utils import shuffle\n",
    "#import XGBoost\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "\n",
    "# Initialize LeaveOneOut\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# Lists to store actual values and predictions from each fold\n",
    "y_true_all = []\n",
    "y_pred_all = []\n",
    "\n",
    "# --- Choose your Ridge approach ---\n",
    "# Option 1: Fixed Alpha\n",
    "#ridge_alpha = 1.0 # Choose an appropriate alpha\n",
    "#model_to_use = Ridge(alpha=ridge_alpha)\n",
    "\n",
    "# Option 2: Tuned Alpha using RidgeCV (performs internal CV to find best alpha)\n",
    "# Note: RidgeCV fits on the whole train split using the found best alpha.\n",
    "# If you need alpha tuned PER fold for the LOOCV prediction, you'd need a nested loop.\n",
    "# For simplicity, let's stick to fixed alpha here based on the request structure.\n",
    "\n",
    "\n",
    "print(f\"Starting LOOCV for {len(y)} samples...\")\n",
    "\n",
    "# Assuming X and y are your input data and target values\n",
    "X, y, person_ids = shuffle(X, y, person_ids) # Shuffle data with a fixed random seed\n",
    "\n",
    "# Loop through LOOCV splits\n",
    "for train_index, test_index in loo.split(X):\n",
    "\n",
    "    model_to_use = LinearRegression() # cv=5 for inner loop tuning\n",
    "\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Train the Ridge model\n",
    "    model_to_use.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the left-out sample\n",
    "    y_pred = model_to_use.predict(X_test)\n",
    "\n",
    "    # Store the actual and predicted values\n",
    "    y_true_all.append(y_test[0])\n",
    "    y_pred_all.append(y_pred[0])\n",
    "\n",
    "print(\"LOOCV finished.\")\n",
    "\n",
    "# Convert lists to numpy arrays for metric calculation\n",
    "y_true_all = np.array(y_true_all).flatten()\n",
    "y_pred_all = np.array(y_pred_all).flatten()\n",
    "\n",
    "# Calculate final metrics based on aggregated predictions\n",
    "mse = mean_squared_error(y_true_all, y_pred_all)\n",
    "r2 = r2_score(y_true_all, y_pred_all)\n",
    "correlation, p_value = pearsonr(y_true_all, y_pred_all)\n",
    "\n",
    "print(f\"\\n--- LOOCV Results (N={len(y_true_all)}) ---\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"R-squared (R2): {r2:.4f}\")\n",
    "print(f\"Pearson Correlation: {correlation:.4f}\")\n",
    "print(f\"P-value for Correlation: {p_value:.4f}\")\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "predictions_df = pd.DataFrame({\n",
    "    'Person ID': person_ids,\n",
    "    'True Values': y_true_all,\n",
    "    'Predicted Values': y_pred_all.round(2),\n",
    "})\n",
    "# Order by Person ID\n",
    "predictions_df.sort_values(by='Person ID', inplace=True)\n",
    "modality_suffix = \"text\"\n",
    "predictions_df.to_csv(f'predictions{modality_suffix}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d87067f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating 38 data points.\n",
      "\n",
      "--- Evaluation Results for: Audio Only - Attention-based Pooling ---\n",
      "R-squared (R2):               0.2951\n",
      "Mean Squared Error (MSE):     1.3171\n",
      "Mean Absolute Error (MAE):    0.9280\n",
      "Pearson Correlation:          0.5923\n",
      "P-value (for Correlation):    0.0001\n",
      "Concordance Correlation Coefficient (CCC): 0.5813\n",
      "---------------------------------------------\n",
      "  (Correlation is statistically significant at p < 0.05)\n",
      "---------------------------------------------\n",
      "\n",
      "--- Evaluation Results for: Text Only - Attention-based Pooling ---\n",
      "R-squared (R2):               0.3348\n",
      "Mean Squared Error (MSE):     1.2429\n",
      "Mean Absolute Error (MAE):    0.9107\n",
      "Pearson Correlation:          0.5921\n",
      "P-value (for Correlation):    0.0001\n",
      "Concordance Correlation Coefficient (CCC): 0.5581\n",
      "---------------------------------------------\n",
      "  (Correlation is statistically significant at p < 0.05)\n",
      "---------------------------------------------\n",
      "\n",
      "--- Evaluation Results for: Fused (Simple Average) ---\n",
      "R-squared (R2):               0.4116\n",
      "Mean Squared Error (MSE):     1.0994\n",
      "Mean Absolute Error (MAE):    0.8541\n",
      "Pearson Correlation:          0.6454\n",
      "P-value (for Correlation):    0.0000\n",
      "Concordance Correlation Coefficient (CCC): 0.6072\n",
      "---------------------------------------------\n",
      "  (Correlation is statistically significant at p < 0.05)\n",
      "---------------------------------------------\n",
      "\n",
      "Fused predictions saved to 'fused_predictions_avg.csv'.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# *** MODIFIED: Corrected CCCLoss Implementation ***\n",
    "def CCCLoss(x, y):\n",
    "    \"\"\"\n",
    "    Calculates the Concordance Correlation Coefficient (CCC) Loss.\n",
    "    CCC measures the agreement between two variables.\n",
    "    Loss = 1 - CCC, because loss functions are minimized, while CCC is maximized.\n",
    "    \"\"\"\n",
    "    # Check if inputs are tensors\n",
    "    if not isinstance(x, torch.Tensor) or not isinstance(y, torch.Tensor):\n",
    "        # Convert inputs to tensors\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "        y = torch.tensor(y, dtype=torch.float32)\n",
    "    # Ensure inputs are flat tensors\n",
    "    x = x.view(-1)\n",
    "    y = y.view(-1)\n",
    "\n",
    "    # Calculate means\n",
    "    mean_x = torch.mean(x)\n",
    "    mean_y = torch.mean(y)\n",
    "\n",
    "    # Calculate variances using population variance (unbiased=False)\n",
    "    var_x = torch.var(x, unbiased=False)\n",
    "    var_y = torch.var(y, unbiased=False)\n",
    "\n",
    "    # Calculate covariance between x and y (population covariance)\n",
    "    cov_xy = torch.mean((x - mean_x) * (y - mean_y))\n",
    "\n",
    "    # Calculate CCC\n",
    "    numerator = 2 * cov_xy\n",
    "    denominator = var_x + var_y + (mean_x - mean_y)**2\n",
    "\n",
    "    # Add a small epsilon for numerical stability (prevents division by zero)\n",
    "    epsilon = 1e-8\n",
    "    ccc = numerator / (denominator + epsilon)\n",
    "\n",
    "    # Return 1 - CCC because loss functions should be minimized\n",
    "    return 1.0 - ccc\n",
    "# *** END MODIFICATION ***\n",
    "\n",
    "# ------------------- 1. Load Your Data -------------------\n",
    "# Replace the CSV paths with your actual files\n",
    "predictions_audio_np = pd.read_csv(\"predictions-audio-attention-ccc.csv\")[\"Predicted Values\"].values\n",
    "true_values_np       = pd.read_csv(\"predictions-audio-attention-ccc.csv\")[\"True Values\"].values\n",
    "predictions_text_np  = pd.read_csv(\"predictions-text-attention-ccc.csv\")[\"Predicted Values\"].values\n",
    "\n",
    "# Ensure they are NumPy arrays\n",
    "true_values_np       = np.array(true_values_np)\n",
    "predictions_audio_np = np.array(predictions_audio_np)\n",
    "predictions_text_np = np.array(predictions_text_np)\n",
    "\n",
    "# Check if lengths match\n",
    "assert len(true_values_np) == len(predictions_audio_np) == len(predictions_text_np), \\\n",
    "       \"Error: True values and all prediction arrays must have the same length.\"\n",
    "\n",
    "all_predictions = [predictions_audio_np, predictions_text_np]\n",
    "\n",
    "# ------------------- 2. Evaluation Function (with MAE) -------------------\n",
    "def evaluate_predictions(true_vals, pred_vals, model_name=\"Model\"):\n",
    "    \"\"\"Calculates and prints R2, MSE, MAE, Pearson Correlation, and p-value.\"\"\"\n",
    "    # Correlation\n",
    "    if len(true_vals) < 2:\n",
    "        print(f\"Warning: Need at least 2 data points for correlation for {model_name}.\")\n",
    "        corr, p_value = np.nan, np.nan\n",
    "    else:\n",
    "        corr, p_value = pearsonr(true_vals, pred_vals)\n",
    "\n",
    "    # Metrics\n",
    "    r2  = r2_score(true_vals, pred_vals)\n",
    "    mse = mean_squared_error(true_vals, pred_vals)\n",
    "    mae = mean_absolute_error(true_vals, pred_vals)\n",
    "    ccc = 1 - CCCLoss(torch.tensor(true_vals), torch.tensor(pred_vals)).item()\n",
    "\n",
    "    # Output\n",
    "    print(f\"\\n--- Evaluation Results for: {model_name} ---\")\n",
    "    print(f\"R-squared (R2):               {r2:.4f}\")\n",
    "    print(f\"Mean Squared Error (MSE):     {mse:.4f}\")\n",
    "    print(f\"Mean Absolute Error (MAE):    {mae:.4f}\")\n",
    "    print(f\"Pearson Correlation:          {corr:.4f}\")\n",
    "    print(f\"P-value (for Correlation):    {p_value:.4f}\")\n",
    "    print(f\"Concordance Correlation Coefficient (CCC): {ccc:.4f}\")\n",
    "    print(\"---------------------------------------------\")\n",
    "    if not np.isnan(p_value):\n",
    "        if p_value < 0.05:\n",
    "            print(\"  (Correlation is statistically significant at p < 0.05)\")\n",
    "        else:\n",
    "            print(\"  (Correlation is not statistically significant at p < 0.05)\")\n",
    "    print(\"---------------------------------------------\")\n",
    "\n",
    "# ------------------- 3. Run Evaluation -------------------\n",
    "print(f\"\\nEvaluating {len(true_values_np)} data points.\")\n",
    "\n",
    "# Audio-only\n",
    "evaluate_predictions(true_values_np, predictions_audio_np, \"Audio Only - Attention-based Pooling\")\n",
    "\n",
    "# Text-only\n",
    "evaluate_predictions(true_values_np, predictions_text_np,    \"Text Only - Attention-based Pooling\")\n",
    "\n",
    "# Simple average fusion\n",
    "fused_predictions_avg_np = np.average(all_predictions, axis=0, weights=[0.5, 0.5])\n",
    "evaluate_predictions(true_values_np, fused_predictions_avg_np, \"Fused (Simple Average)\")\n",
    "\n",
    "# Save fused predictions\n",
    "fused_predictions_avg_df = pd.DataFrame({\n",
    "    'True Values': true_values_np,\n",
    "    'Fused Predictions (Average)': np.round(fused_predictions_avg_np, 2)\n",
    "})\n",
    "fused_predictions_avg_df.to_csv('fused_predictions_avg.csv', index=False)\n",
    "\n",
    "print(\"\\nFused predictions saved to 'fused_predictions_avg.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700b0966",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
